{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional libraries you will use for this assignment in this block\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Play Golf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>True</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>True</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>True</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rainy</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Normal</td>\n",
       "      <td>True</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>True</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>Normal</td>\n",
       "      <td>False</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>True</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Outlook  Temp Humidity  Windy Play Golf\n",
       "0      Rainy   Hot     High  False        No\n",
       "1      Rainy   Hot     High   True        No\n",
       "2   Overcast   Hot     High  False       Yes\n",
       "3      Sunny  Mild     High  False       Yes\n",
       "4      Sunny  Cool   Normal  False       Yes\n",
       "5      Sunny  Cool   Normal   True        No\n",
       "6   Overcast  Cool   Normal   True       Yes\n",
       "7      Rainy  Mild     High  False        No\n",
       "8      Rainy  Cool   Normal  False       Yes\n",
       "9      Sunny  Mild   Normal  False       Yes\n",
       "10     Rainy  Mild   Normal   True       Yes\n",
       "11  Overcast  Mild     High   True       Yes\n",
       "12  Overcast   Hot   Normal  False       Yes\n",
       "13     Sunny  Mild     High   True        No"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df = pd.read_csv('GolfDataset.csv')\n",
    "Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Play Golf</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlook</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overcast</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rainy</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunny</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Play Golf  No  Yes\n",
       "Outlook           \n",
       "Overcast    0    4\n",
       "Rainy       3    2\n",
       "Sunny       2    3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tbl = pd.crosstab(index = Df['Outlook'], columns = Df['Play Golf'])\n",
    "Tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of days the Outlook was Rainy and the person played golf is: 2\n",
      "The number of days it Outlook was Rainy and the person did not play golf is: 3\n",
      "\n",
      "\n",
      "The proability of playing golf given it is rainy\n",
      "p(Playing Golf = Yes|Outlook = 'Rainy') is: 0.4\n",
      "\n",
      "\n",
      "The proability of not playing golf given it is rainy\n",
      "p(Playing Golf = No|Outlook = 'Rainy') is: 0.6\n"
     ]
    }
   ],
   "source": [
    "rYes = Tbl.loc['Rainy']['Yes']\n",
    "rNo = Tbl.loc['Rainy']['No']\n",
    "\n",
    "print(str(\"The number of days the Outlook was Rainy and the person played golf is: \" + str(rYes)))\n",
    "print(str(\"The number of days it Outlook was Rainy and the person did not play golf is: \" + str(rNo)))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(str(\"The proability of playing golf given it is rainy\"+ '\\n'+ \\\n",
    "          \"p(Playing Golf = Yes|Outlook = 'Rainy') is: \" + str(rYes/(rYes+rNo))))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(str(\"The proability of not playing golf given it is rainy\"+ '\\n'+ \\\n",
    "          \"p(Playing Golf = No|Outlook = 'Rainy') is: \" + str(rNo/(rYes+rNo))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Write a function to compute Gini Index of a given split.\n",
    "</div>\n",
    "\n",
    "Note that Gini index of a feature is given by: \n",
    "\n",
    "$$ Gini_{split}(\\mathrm{feature})  = \\sum_{i = 1}^k \\frac{n_i}{n} Gini(\\mathrm{feature} = t_i)$$\n",
    "\n",
    "where,\n",
    "\n",
    "$n_i$ is the number of records at child $i$\n",
    "\n",
    "$n$ is the number of records at parent $p$\n",
    "\n",
    "$$ Gini(\\mathrm{feature} = t_i)  = 1 - \\sum_{c \\in C} p(\\mathrm{class} = c | \\mathrm{feature} = t_i)^2$$\n",
    "\n",
    "where,\n",
    "\n",
    "$C$ is the set of classes\n",
    "\n",
    "\n",
    "As indicated below, your function should accept a dataframe similar to the contingency `Tbl` defined above. I recommend writing two functions, one for computing $Gini(\\mathrm{feature} = t_i)$ which you can use to compute $Gini_{split}(\\mathrm{feature})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeGiniFeature(TblRow):\n",
    "    # Note that TblRow should be a list or 1-dimensional numpy array obtained using Tbl.loc[ix].values\n",
    "    # Your code here\n",
    "    giniFeature=0\n",
    "    for i in range(len(TblRow)):\n",
    "        p=TblRow[i]/sum(TblRow)\n",
    "        giniFeature += p**2\n",
    "    giniFeature = 1-giniFeature\n",
    "\n",
    "    return(giniFeature)\n",
    "\n",
    "\n",
    "def computeGiniSplit(Tbl):\n",
    "    \n",
    "    # Initialize additional variables if necessary\n",
    "    giniSplit = 0\n",
    "    for ix, row in Tbl.iterrows():\n",
    "        # You can call the computeGiniFeature(Tbl.loc[ix]) here for every row in Tbl  \n",
    "        # and combine the values to obtain the final giniSplit\n",
    "        TblRow = Tbl.loc[ix].values # Try not to change this part of the code\n",
    "        giniFeature = computeGiniFeature(TblRow)\n",
    "        # Your code here\n",
    "        a= TblRow.sum()\n",
    "        b=Tbl.sum().sum()\n",
    "        giniSplit += a/b*giniFeature\n",
    "        \n",
    "    return(giniSplit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Write a function to compute Entropy of a given split. \n",
    "</div>\n",
    "\n",
    "Note that Entropy of a feature is given by: \n",
    "\n",
    "$$ Entropy_{split}(\\mathrm{feature})  = \\sum_{i = 1}^k \\frac{n_i}{n} Entropy(\\mathrm{feature} = t_i)$$\n",
    "\n",
    "where,\n",
    "\n",
    "$n_i$ is the number of records at child $i$\n",
    "\n",
    "$n$ is the number of records at parent $p$\n",
    "\n",
    "$$ Entropy(\\mathrm{feature} = t_i)  =  - \\sum_{c \\in C} p(c | t_i)\\log_2 p(c | t_i)$$\n",
    "\n",
    "where,\n",
    "\n",
    "$C$ is the set of classes\n",
    "\n",
    "\n",
    "As indicated below, your function should accept a dataframe similar to the contingency `Tbl` defined above. I recommend writing two functions, one for computing $Entropy(\\mathrm{feature} = t_i)$ which you can use to compute $Entropy_{split}(\\mathrm{feature})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEntropyFeature(TblRow):\n",
    "    entropyFeature=0\n",
    "    for i in range(len(TblRow)):\n",
    "        p=TblRow[i]/sum(TblRow)\n",
    "        if p==0:\n",
    "            continue\n",
    "        entropyFeature -= p*np.log2(p)\n",
    "    return(entropyFeature)\n",
    "\n",
    "def computeEntropySplit(Tbl):\n",
    "    \n",
    "    # Initialize additional variables if necessary\n",
    "    entropySplit = 0\n",
    "    for ix, row in Tbl.iterrows():\n",
    "        # You can call the computeEntropyFeature(Tbl.loc[ix]) here for every row in Tbl  \n",
    "        # and combine the values to obtain the final entropySplit\n",
    "        TblRow = Tbl.loc[ix].values # Try not to change this part of the code\n",
    "        entropyFeature = computeEntropyFeature(TblRow)\n",
    "        # Your code here\n",
    "        a= TblRow.sum()\n",
    "        b=Tbl.sum().sum()\n",
    "        entropySplit += a/b*entropyFeature\n",
    "        \n",
    "    return(entropySplit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "To identify the root node for the decision tree, based on the information gain computed.\n",
    "</div>\n",
    "\n",
    "$$ Information Gain(\\textrm{feature} = f)  = P - M(f)$$\n",
    "\n",
    "where,\n",
    "\n",
    " $P$ is the Gini index before split, and\n",
    " \n",
    " $ M(f)$  is the Gini Index of the feature f\n",
    " \n",
    "Note that since computeGiniFeature() accepts a list of values, you should be able to compute $P$ using computeGiniFeature() function by passing the appropriate list as input. Same goes for computing InformationGain using Entropy as impurity measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information gain of Gini for Outlook as root node is: 0.11632653061224485\n",
      "\n",
      "\n",
      "Information gain of Gini for Temp as root node is: 0.018707482993197244\n",
      "\n",
      "\n",
      "Information gain of Gini for Humidity as root node is: 0.09183673469387743\n",
      "\n",
      "\n",
      "Information gain of Gini for Windy as root node is: 0.030612244897959162\n",
      "\n",
      "\n",
      "Outlook with max.IG shall be picked as root node\n",
      "***************************************************\n",
      "\n",
      "\n",
      "Information gain of Entropy for Outlook as root node is: 0.24674981977443933\n",
      "\n",
      "\n",
      "Information gain of Entropy for Temp as root node is: 0.02922256565895487\n",
      "\n",
      "\n",
      "Information gain of Entropy for Humidity as root node is: 0.15183550136234159\n",
      "\n",
      "\n",
      "Information gain of Entropy for Windy as root node is: 0.04812703040826949\n",
      "\n",
      "\n",
      "Outlook with max.IG shall be picked as root node\n",
      "***************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%    \n",
    "tab_label= Df['Play Golf'].value_counts()\n",
    "P=computeGiniFeature(tab_label)\n",
    "M=[]\n",
    "for i in range(len(Df.columns)-1):\n",
    "    Tbl = pd.crosstab(index = Df.iloc[:,i], columns = Df.iloc[:,-1])\n",
    "    M.append(computeGiniSplit(Tbl))\n",
    "    print(str(\"Information gain of Gini for \" + Df.columns[i] +\" as root node is: \" + str(P-M[i])))\n",
    "    print(\"\\n\")\n",
    "IG= []\n",
    "IG= P-M    \n",
    "maxcol= IG.argmax()\n",
    "print(str(Df.columns.values[maxcol] + \" with max.IG shall be picked as root node\"))\n",
    "print('***************************************************')\n",
    "print(\"\\n\")\n",
    "\n",
    "#%%\n",
    "P=computeEntropyFeature(tab_label)\n",
    "M=[]\n",
    "for i in range(len(Df.columns)-1):\n",
    "    Tbl = pd.crosstab(index = Df.iloc[:,i], columns = Df.iloc[:,-1])\n",
    "    M.append(computeEntropySplit(Tbl))\n",
    "    print(str(\"Information gain of Entropy for \" + Df.columns[i] +\" as root node is: \" + str(P-M[i])))\n",
    "    print(\"\\n\")\n",
    "IG= []\n",
    "IG= P-M \n",
    "maxcol= IG.argmax()\n",
    "print(str(Df.columns.values[maxcol] + \" with max.IG shall be picked as root node\"))\n",
    "print('***************************************************')\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "Computing the InformationGain using Gini index as the impurity measure. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information gain of Gini for Temp as child of Rainy is: 0.27999999999999997\n",
      "\n",
      "\n",
      "Information gain of Gini for Humidity as child of Rainy is: 0.48\n",
      "\n",
      "\n",
      "Information gain of Gini for Windy as child of Rainy is: 0.013333333333333308\n",
      "\n",
      "\n",
      "Temp with max.IG shall be picked as child of Rainy\n",
      "***************************************************\n",
      "\n",
      "\n",
      "Overcast is a leaf node \n",
      "***************************************************\n",
      "\n",
      "\n",
      "Information gain of Gini for Temp as child of Sunny is: 0.013333333333333308\n",
      "\n",
      "\n",
      "Information gain of Gini for Humidity as child of Sunny is: 0.013333333333333308\n",
      "\n",
      "\n",
      "Information gain of Gini for Windy as child of Sunny is: 0.48\n",
      "\n",
      "\n",
      "Humidity with max.IG shall be picked as child of Sunny\n",
      "***************************************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "Df_out = Df['Outlook'].unique()\n",
    "for j in range(len(Df_out)):\n",
    "    Df_out_split = (Df[Df['Outlook']== Df_out[j]])\n",
    "    Df_out_split = Df_out_split.drop(columns=['Outlook'])\n",
    "    \n",
    "    if len(Df_out_split['Play Golf'].unique()) > 1:\n",
    "        \n",
    "        tab_label= Df_out_split['Play Golf'].value_counts()\n",
    "        P=computeGiniFeature(tab_label)\n",
    "        M=[]\n",
    "        for i in range(len(Df_out_split.columns)-1):\n",
    "            Tbl = pd.crosstab(index = Df_out_split.iloc[:,i], columns = Df_out_split.iloc[:,-1])\n",
    "            M.append(computeGiniSplit(Tbl))\n",
    "            print(str(\"Information gain of Gini for \" + Df_out_split.columns[i] + \\\n",
    "                      \" as child of \" + Df_out[j] + \" is: \" + str(P-M[i])))\n",
    "            print(\"\\n\")\n",
    "        IG= []\n",
    "        IG= P-M    \n",
    "        maxcol= IG.argmax()\n",
    "        print(str(Df.columns.values[maxcol] + \" with max.IG shall be picked as child of \" + Df_out[j]))\n",
    "        print('***************************************************')\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    else:\n",
    "        print(str(Df_out[j] + \" is a leaf node \"))\n",
    "        print('***************************************************')\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 28)\n",
      "27 features and 4 classes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "s     59\n",
       "d     54\n",
       "h     48\n",
       "o     37\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Based on the data provided in `ForestTypes/training.csv`. How may features and classes are in this dataset?\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Df = pd.read_csv('ForestTypes/training.csv')\n",
    "print(Df.shape)\n",
    "print('27 features and 4 classes')\n",
    "Df.iloc[:,0].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using data in `ForestTypes/training.csv` build a Logisitc Regression Classifier.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "# The following line ensures our plots appear in-line, \n",
    "# as opposed to appearing in a new window.\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Df_training = pd.read_csv('ForestTypes/training.csv')\n",
    "Df_training.shape\n",
    "Df_training.iloc[:,0].value_counts()\n",
    "\n",
    "Df_testing = pd.read_csv('ForestTypes/testing.csv')\n",
    "Df_testing.shape\n",
    "Df_testing.iloc[:,0].value_counts()\n",
    "\n",
    "predictors = Df_training.columns[1:]\n",
    "X_train = Df_training.loc[:,predictors]\n",
    "X_test = Df_testing.loc[:,predictors]\n",
    "y_train = Df_training.iloc[:,0]\n",
    "le =LabelEncoder() # Initilaize Data Encoder\n",
    "le.fit(y_train) # Fit encoder to data\n",
    "y_train = le.transform(y_train)\n",
    "y_test = Df_testing.iloc[:,0]\n",
    "le.fit(y_test)\n",
    "y_test = le.transform(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 85.23%:\n"
     ]
    }
   ],
   "source": [
    "sklearn_logistic = LogisticRegression(solver='liblinear')\n",
    "sklearn_logistic.fit(X_train, y_train)\n",
    "#print(sklearn_logistic.intercept_, sklearn_logistic.coef_)\n",
    "sklearn_predict = sklearn_logistic.predict(X_test)\n",
    "pd.Series(sklearn_predict).value_counts()\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "Accuracy = metrics.accuracy_score(y_test, sklearn_predict)\n",
    "print('The accuracy is %.2f%%:' %(Accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "Using data in `ForestTypes/training.csv` build a SVM with a polynomial kernel. Perform 5-fold cross validation on the training data to identify the best choice of parameters C and degree. Try the following values for parameter search:\n",
    "    \n",
    "   - Penalty parameter C of the error term: C = 1, 5, 10\n",
    "   - Degree of the polynomial kernel function (‘poly’): degree = 2, 3\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "# The following line ensures our plots appear in-line, \n",
    "# as opposed to appearing in a new window.\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df_training = pd.read_csv('ForestTypes/training.csv')\n",
    "Df_training.shape\n",
    "Df_training.iloc[:,0].value_counts()\n",
    "Df_testing = pd.read_csv('ForestTypes/testing.csv')\n",
    "Df_testing.shape\n",
    "Df_testing.iloc[:,0].value_counts()\n",
    "\n",
    "\n",
    "predictors = Df_training.columns[1:]\n",
    "X_train = Df_training.loc[:,predictors]\n",
    "X_test = Df_testing.loc[:,predictors]\n",
    "\n",
    "y_train = Df_training.iloc[:,0]\n",
    "le =LabelEncoder() # Initilaize Data Encoder\n",
    "le.fit(y_train) # Fit encoder to data\n",
    "y_train = le.transform(y_train)\n",
    "y_test = Df_testing.iloc[:,0]\n",
    "le.fit(y_test)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'C': 10, 'degree': 3, 'kernel': 'poly'}, 0.9698717948717949)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = [\n",
    "              {'C': [1, 5, 10], 'degree': [2, 3], 'kernel': ['poly']},\n",
    "              ]\n",
    "grid_svc = GridSearchCV(estimator = SVC(),param_grid =parameters,scoring='accuracy',cv=5,verbose =1)\n",
    "\n",
    "grid_svc.fit(X_train,y_train)\n",
    "\n",
    "grid_svc.best_params_, grid_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 84.31%:\n"
     ]
    }
   ],
   "source": [
    "pred_svc = grid_svc.predict(X_test)\n",
    "Accuracy = metrics.accuracy_score(y_test,pred_svc)\n",
    "print('The accuracy is %.2f%%:' %(Accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the grid search cross validation, the C = 10, degree = 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is compared with the original paper that published this data here: http://www.cr.chiba-u.jp/~tateishi-lab/pdf/2011/Using%20geographically%202011.pdf .\n",
    "The paper is using the RBF kernel, with C=1010, $\\gamma$ = 0.003 and 1.95 for 27 and 9 variables.\n",
    "The accuracies are 82.2\\% for 9 variables and 85.9\\% for 27 variables.\n",
    "Compared with results here 84.3\\% using polynominal kernel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
